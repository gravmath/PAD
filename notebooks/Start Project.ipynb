{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import shutil\n",
    "sys.path.append('../src')\n",
    "import Scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def inventory_file(filename,base_dir,download_dir):\n",
    "    \"\"\"inventory_file is designed to take a filename and place it into the\n",
    "       appropriate directory (creating the directory if required) based on the\n",
    "       MMS science conventions.  The terminal and source directories are always\n",
    "       relative to variables base_dir (and curr_dir) and download_dir that\n",
    "       are input (except curr_dir, which is base_dir dressed locally)\"\"\"\n",
    "    \n",
    "    #pieces is an array that contains the separate descriptors of a science file\n",
    "    pieces    = filename.split('_')\n",
    "    mode      = pieces[2]\n",
    "    epoch_str = pieces[-2]\n",
    "    year      = epoch_str[0:4]\n",
    "    month     = epoch_str[4:6]\n",
    "    day       = epoch_str[6:8]\n",
    "\n",
    "    #get rid of the epoch_str and file version\n",
    "    del pieces[-1]\n",
    "    del pieces[-1]\n",
    "    \n",
    "    #put year and month into pieces\n",
    "    pieces.append(year)\n",
    "    pieces.append(month)\n",
    "    \n",
    "    if mode == 'brst':\n",
    "        pieces.append(day)\n",
    "    \n",
    "    #now that all the pieces are available start making the directories\n",
    "    curr_dir = base_dir\n",
    "    print pieces\n",
    "    for p in pieces:\n",
    "        print curr_dir\n",
    "        curr_dir = curr_dir+'/'+p\n",
    "        if os.path.isdir(curr_dir):\n",
    "            pass\n",
    "        else:\n",
    "            os.mkdir(curr_dir)\n",
    "            \n",
    "    #finally move the file into that directory\n",
    "    try:\n",
    "        shutil.move(download_dir+'/'+filename,curr_dir+'/'+filename)\n",
    "        return True\n",
    "    except:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_dir               = 'z:/data/ftp/'\n",
    "download_dir           = 'c:/Users/cschiff/Downloads/CDFs/'\n",
    "local_dir              = 'c:/Yuggoth/'\n",
    "#base_dir               = local_dir\n",
    "\n",
    "#scan_or_load           = 'scan'\n",
    "scan_or_load           = 'load'\n",
    "obs                    = 'mms1'\n",
    "#scanned_files_filename = 'c:/Users/cschiff/Documents/github/scanned_files_%s.fpiprd1' % (obs,)\n",
    "scanned_files_filename = 'c:/Users/cschiff/Documents/github/scanned_files_%s.local' % (obs,)\n",
    "\n",
    "start_time_brst = '2015-12-21 10:20:00'\n",
    "stop_time_brst  = '2015-12-21 11:00:00'\n",
    "start_time_fast = '2015-12-20 00:00:00'\n",
    "stop_time_fast  = '2015-12-22 00:00:00'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if scan_or_load == 'scan':\n",
    "    bpsd_fast_dict         = Scraper.get_my_l2_files(obs,'dsp','fast','bpsd',base_dir)\n",
    "    epsd_fast_dict         = Scraper.get_my_l2_files(obs,'dsp','fast','epsd',base_dir)\n",
    "    scpot_fast_dict        = Scraper.get_my_l2_files(obs,'edp','fast','scpot',base_dir)\n",
    "    dce_brst_dict          = Scraper.get_my_l2_files(obs,'edp','brst','dce',base_dir)\n",
    "    fgm_brst_dict          = Scraper.get_my_l2_files(obs,'fgm','brst','',base_dir)\n",
    "    fpi_brst_des_dist_dict = Scraper.get_my_l2_files(obs,'fpi','brst','des-dist',base_dir)\n",
    "    fpi_brst_dis_dist_dict = Scraper.get_my_l2_files(obs,'fpi','brst','dis-dist',base_dir)\n",
    "    fpi_fast_des_dist_dict = Scraper.get_my_l2_files(obs,'fpi','fast','des-dist',base_dir)\n",
    "    fpi_fast_dis_dist_dict = Scraper.get_my_l2_files(obs,'fpi','fast','dis-dist',base_dir)\n",
    "    fpi_brst_des_moms_dict = Scraper.get_my_l2_files(obs,'fpi','brst','des-moms',base_dir)\n",
    "    fpi_brst_dis_moms_dict = Scraper.get_my_l2_files(obs,'fpi','brst','dis-moms',base_dir)\n",
    "    fpi_fast_des_moms_dict = Scraper.get_my_l2_files(obs,'fpi','fast','des-moms',base_dir)\n",
    "    fpi_fast_dis_moms_dict = Scraper.get_my_l2_files(obs,'fpi','fast','dis-moms',base_dir)\n",
    "    mec_srvy_epht89d_dict  = Scraper.get_my_l2_files(obs,'mec','srvy','epht89d',base_dir)\n",
    "    scanned_files = open(scanned_files_filename, \"w\")\n",
    "    pickle.dump(bpsd_fast_dict,scanned_files)         \n",
    "    pickle.dump(epsd_fast_dict,scanned_files)         \n",
    "    pickle.dump(scpot_fast_dict,scanned_files)        \n",
    "    pickle.dump(dce_brst_dict,scanned_files)          \n",
    "    pickle.dump(fgm_brst_dict,scanned_files)\n",
    "    pickle.dump(fpi_brst_des_dist_dict,scanned_files) \n",
    "    pickle.dump(fpi_brst_dis_dist_dict,scanned_files) \n",
    "    pickle.dump(fpi_fast_des_dist_dict,scanned_files) \n",
    "    pickle.dump(fpi_fast_dis_dist_dict,scanned_files) \n",
    "    pickle.dump(fpi_brst_des_moms_dict,scanned_files) \n",
    "    pickle.dump(fpi_brst_dis_moms_dict,scanned_files) \n",
    "    pickle.dump(fpi_fast_des_moms_dict,scanned_files) \n",
    "    pickle.dump(fpi_fast_dis_moms_dict,scanned_files) \n",
    "    pickle.dump(mec_srvy_epht89d_dict,scanned_files)\n",
    "    scanned_files.close()\n",
    "else:\n",
    "    scanned_files          = open(scanned_files_filename,\"r\")\n",
    "    bpsd_fast_dict         = pickle.load(scanned_files)\n",
    "    epsd_fast_dict         = pickle.load(scanned_files)\n",
    "    scpot_fast_dict        = pickle.load(scanned_files)\n",
    "    dce_brst_dict          = pickle.load(scanned_files)\n",
    "    fgm_brst_dict          = pickle.load(scanned_files)\n",
    "    fpi_brst_des_dist_dict = pickle.load(scanned_files)\n",
    "    fpi_brst_dis_dist_dict = pickle.load(scanned_files)\n",
    "    fpi_fast_des_dist_dict = pickle.load(scanned_files)\n",
    "    fpi_fast_dis_dist_dict = pickle.load(scanned_files)\n",
    "    fpi_brst_des_moms_dict = pickle.load(scanned_files)\n",
    "    fpi_brst_dis_moms_dict = pickle.load(scanned_files)\n",
    "    fpi_fast_des_moms_dict = pickle.load(scanned_files)\n",
    "    fpi_fast_dis_moms_dict = pickle.load(scanned_files)\n",
    "    mec_srvy_epht89d_dict  = pickle.load(scanned_files)\n",
    "    scanned_files.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_files = {'bpsd_f':[],\n",
    "            'epsd_f':[],\n",
    "            'scpot_f':[],\n",
    "            'dce_b':[],\n",
    "            'fgm_b':[],\n",
    "            'des-dist_b':[],\n",
    "            'dis-dist_b':[],\n",
    "            'des-moms_b':[],\n",
    "            'dis-moms_b':[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_files['bpsd_f']     = Scraper.limit_time_range(start_time_fast,stop_time_fast,bpsd_fast_dict)\n",
    "my_files['epsd_f']     = Scraper.limit_time_range(start_time_fast,stop_time_fast,epsd_fast_dict)\n",
    "my_files['scpot_f']    = Scraper.limit_time_range(start_time_fast,stop_time_fast,scpot_fast_dict)\n",
    "my_files['dce_b']      = Scraper.limit_time_range(start_time_brst,stop_time_brst,dce_brst_dict)\n",
    "my_files['fgm_b']      = Scraper.limit_time_range(start_time_brst,stop_time_brst,fgm_brst_dict)\n",
    "my_files['des-dist_b'] = Scraper.limit_time_range(start_time_brst,stop_time_brst,fpi_brst_des_dist_dict)\n",
    "my_files['dis-dist_b'] = Scraper.limit_time_range(start_time_brst,stop_time_brst,fpi_brst_dis_dist_dict)\n",
    "my_files['des-moms_b'] = Scraper.limit_time_range(start_time_brst,stop_time_brst,fpi_brst_des_moms_dict)\n",
    "my_files['dis-moms_b'] = Scraper.limit_time_range(start_time_brst,stop_time_brst,fpi_brst_dis_moms_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for k in my_files.keys():\n",
    "#k = 'scpot_f'\n",
    "#for f in my_files[k]:\n",
    "#        bf = os.path.basename(f)\n",
    "#        print bf\n",
    "#        shutil.copy(f,download_dir+bf)      \n",
    "#        inventory_file(bf,local_dir,download_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "prj_file = open('c:/Users/cschiff/Documents/github/Dec_12_21_mms1.project','w')\n",
    "pickle.dump(my_files,prj_file)\n",
    "prj_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
